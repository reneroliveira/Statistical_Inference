\documentclass[a4paper,10pt, notitlepage]{report}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage[portuguese]{babel}
\usepackage{amsmath}%
\usepackage{MnSymbol}%
%\usepackage{wasysym}%

\newtheorem{defi}{Definicão}
\newtheorem{teo}{Teorema}
\newtheorem{col}{Corolário}
\setlength{\parindent}{0em}
\newcommand{\indep}{\perp \!\!\! \perp} %% indepence
\newcommand{\gt}{>}%broken keyboard
\newcommand{\pow}{^}%broken keyboard
\newcommand{\pr}{\operatorname{Pr}} %% probability
\newcommand{\vr}{\operatorname{Var}} %% variance
\newcommand{\rs}{X_1, X_2, \ldots, X_n} %%  random sample
\newcommand{\irs}{X_1, X_2, \ldots} %% infinite random sample
\newcommand{\rsd}{x_1, x_2, \ldots, x_n} %%  random sample, realised
\newcommand{\Sm}{\bar{X}_n} %%  sample mean, random variable
\newcommand{\sm}{\bar{x}_n} %%  sample mean, realised
\newcommand{\Sv}{\bar{S}^2_n} %%  sample variance, random variable
\newcommand{\sv}{\bar{s}^2_n} %%  sample variance, realised
\newcommand{\bX}{\boldsymbol{X}} %%  random sample, contracted form (bold)
\newcommand{\bx}{\boldsymbol{x}} %%  random sample, realised, contracted form (bold)
\newcommand{\bT}{\boldsymbol{T}} %%  Statistic, vector form (bold)
\newcommand{\bt}{\boldsymbol{t}} %%  Statistic, realised, vector form (bold)
\newcommand{\emv}{\hat{\theta}_{\text{EMV}}}
\newcommand{\defn}{\stackrel{\textrm{\scriptsize def}}{=}}
\newcommand{\mysection}[2]{\setcounter{section}{#1}\addtocounter{section}{-1}\section*{#1 - #2}}
\newcommand{\op}{\operatorname}

% Title Page
\title{Trabalho IV: Testes uniformemente mais poderosos.}
\author{Disciplina: Inferência Estatística \\ Aluno: Rener de Souza Oliveira}

\begin{document}
	\maketitle

	
	\section*{Introdução}
	
	Vimos que os testes de hipótese fornecem uma abordagem matematicamente sólida para traduzir hipóteses científicas sobre o processo gerador dos dados em decisões sobre os dados -- isto é, traduzir afirmações sobre partições do espaço de parâmetros, $\Omega$, em afirmações testáveis sobre o espaço amostral $\mathcal{X}^n$.
	
	Um teste $\delta(\bX)$ é uma decisão (binária) de rejeitar ou não uma hipótese nula ($H_0$) sobre $\theta \in \Omega$ com base em uma amostra $\bX$.
	A capacidade de um teste de rejeitar $H_0$ quando ela é falsa é medida pela função poder, $\pi(\theta |\delta)$.
	Nem todos os testes, no entanto, são criados iguais.
	Em certas situações, é possível mostrar que um procedimento $\delta_A$ é~\textit{uniformemente} mais poderoso que outro procedimento $\delta_B$ para testar a mesma hipótese.
	
	Neste trabalho, vamos definir e aplicar o conceito de~\textbf{teste uniformemente mais poderoso}.
	
	\mysection{1}{Motivação e Definição}
	
	Sejam:
	
	\begin{align}
	\label{h0h1}
	 H_0:& \theta \in \Omega_0\subset \Omega,\nonumber\\
	 H_1:& \theta \in \Omega_1\subset \Omega,\\
	 \text{onde } &\Omega_1= \Omega \setminus \Omega_0\nonumber
	\end{align}
	
	%De tal forma que $H_1$ seja composta, ou seja, possui cardinalidade maior que 1.
	
	Ao realizar um procedimento de teste $\delta(\bX)$, é desejável que a função poder $\pi(\theta|\delta):\defn \op{Pr}(Rejeitar ~H_0|\theta)$ seja menor ou igual à um nível de significância $\alpha_0\in (0,1)$, quando $\theta\in\Omega_0$, limitando superiormente a probabilidade de erro do tipo I (rejeitar $H_0$ quando ela é verdadeira). Podemos expressar tal propriedade da seguinte forma:
	
	\begin{align*}
		\alpha(\delta)\leq \alpha_0
	\end{align*}
	
	Onde $\displaystyle\alpha(\delta):\defn\sup_{\theta\in\Omega_0}\pi(\theta|\delta)$ é o tamanho do teste.
	
	
	
	Além disso, queremos também ter algum controle sobre a probabilidade de erro do tipo II (não rejeitar $H_0$ quando ela é falsa). Como a probabilidade de tal erro quando $\theta \in \Omega_1$ é igual a $1-\pi(\theta|\delta)$, queremos que, na região onde $H_0$ é falsa ($\Omega_1$) a função poder $\pi(\theta|\delta)$ seja máxima, para todo $\theta$ em tal região. Tal maximização, minimiza a probabilidade de erro do tipo II quando $\theta\in\Omega_1$, isso nem sempre é possível, mas quando for, temos um nome especial para esse teste, que segue abaixo sua definição:
	
	\begin{defi}
		\textbf{(Teste Uniformemente mais poderoso)}
		\label{ump} 
		Seja $\mathcal{C}$ uma classe de teste para as hipóteses (\ref{h0h1}); $\delta^*\in\mathcal{C}$ é chamado de uniformemente mais poderoso (UMP\footnote{Uniformly Most Powerful Test}) da classe $\mathcal{C}$, se:
		
		\begin{align*}\pi(\theta|\delta^*)&\geq\pi(\theta|\delta) ~\forall \,\theta \in \Omega_1,
		\end{align*}
		
		para qualquer teste $\delta\in\mathcal{C}$.
		
	\end{defi} 
	Seguindo a motivação dada acima, podemos definir $\mathcal{C}$ como o conjunto de todos dos testes de tamanho menor ou igual a $\alpha_0$, limitando o erro tipo I. Neste caso, chamamos $\delta^*$ de UMP para (\ref{h0h1}) ao nível $\alpha_0$.
	
	\mysection{2}{Razão de Verossimilhança Monótona}
	
	\begin{defi}
		\textbf{(Razão de Verossimilhanças Monótona)} Seja $f_n(\bx|\theta)$ a função de verossimilhança das observações $\bX = (\rs)$, e $T=r(\bX)$ uma estatística. Dizemos que a distribuição dos dados tem \textbf{razão de verossimilhanças monótona} quando, $\forall\,\theta_1,\theta_2\in\Omega; \theta_1<\theta_2$, a razão $\dfrac{f(\bx|\theta_2)}{f(\bx|\theta_1)}$ depende dos dados através de $r(\bx)$ somente, e é uma função monótona de $r(\bx)$ sob seu espaço de definição.
	\end{defi}

	\mysection{3}{UMP para $H_0$ simples}
	
	Considere uma hipótese nula simples, $H_0: \theta = \theta_0$, $\theta_0 \in \Omega$.
	Mostraremos que, se vale o Teorema da Fatorização, e existem $c$ e $\alpha_0$ tais que
	\begin{equation}
	\pr\left(r(\bX) \geq c \mid \theta = \theta_0\right) = \alpha_0\nonumber,
	\end{equation}
	então o procedimento $\delta^\ast$ que rejeita $H_0$ se $r(\bX) \geq c$ é UMP para $H_0$ ao nível $\alpha_0$.
	
	Mas antes, vamos enunciar alguns teoremas:
	
	\begin{teo}
		\textbf{(Teorema da Fatorização)(citar degroot)}
		Sejam $\rs$ amostra aleatória de uma distribuição de densidade ou massa $f(x|\theta)$, onde $\theta\in\Omega$. Uma estatística $T=r(\rs)$ é suficiente para $\theta$, se, e somente se a distribuição conjunta dos dados $f_n(\bx|\theta)$ pode ser fatorizada como:
		
		\begin{align*}
			f_n(\bx|\theta) = u(\bx)v[r(\bx),\theta],
		\end{align*}
		
		para todo $\bx= (\rsd)\in\mathbb{R}^n$, e $\forall \theta \in \Omega$. $u$ e $v$ são funções não negativas.
		
	\end{teo}

	A demostração pode ser encontrada em (degroot 445)
	
	\begin{teo}
		\textbf{(Lema de Neyman-Pearson)(citar casella 388-389)} Seja $(\rs)\in\mathbb{R}^n$ uma amostra indexada por $\theta$. Considere as hipóteses
		
		\begin{align}
		\label{hnp}
		H_0:\theta=\theta_0,\\
		H_1:\theta=\theta_1,\nonumber
		\end{align}
		
		e seja $f_n(\bx|\theta_i)$, com $i=0,1$ a função de densidade ou massa dos dados.
		
		Seja $R\in\mathbb{R}^n$ uma região de rejeição que satisfaça:
		
		\begin{align}
		\label{np1}
			\bx\in R\text{ se } f(\bx|\theta_1)\geq kf(\bx|\theta_0)\nonumber\\ \\\text{ e }\bx\in R^C\text{ se } f(\bx|\theta_1)\leq k f(\bx|\theta_0),\nonumber
		\end{align}
		
		para algum $k\geq0$ e 
		
		\begin{align}
		\label{np2}
			\pr(\bX\in R|\theta = \theta_0)=\alpha_0.
		\end{align}
		
		Então, todo teste que satisfaz (\ref{np1}) e (\ref{np2}) é UMP ao nivel $\alpha_0$.
	\end{teo}

	A demostração será omitida pois pode ser encontrada em (citar casella).
	
	\begin{col}
		\label{colnp}
		Considere as hipóteses (\ref{hnp}). Seja $T(\bX)$ uma estatística suficiente para $\theta$ e $g(t|\theta_i)\,i=0,1$, uma função de $t=T(\bx)$ tal que fatoriza a verossimilhança dos dados em $f_n(\bx|\theta_i)=g(t|\theta_i)u(\bx)$, para alguma função $u(\bx)\geq0$.
		
		Seja $\delta$ um teste que rejeite $H_0$ se $T$ pertence a uma região de rejeição $S$ (subconjunto do espaço de definição de $T$). Assim, $\delta$ será UMP ao nível $\alpha_0$ se satisfazer:
		
		\begin{align}
		\label{col1}
		 g(t|\theta_1)\geq  kg(t|\theta_0)\implies t\in S\nonumber\\ \\\text{ e }g(t|\theta_1)\leq kg(t|\theta_0)\implies t\in S\pow C,\nonumber
		\end{align}
		
		para algum $k\geq0$ e 
		
		\begin{align}
		\label{col2}
		\pr[T(\bX)\in S|\theta = \theta_0]=\alpha_0.
		\end{align}
		
	\end{col}
	\textbf{Demonstração:} Definindo $R=\{\bx|T(\bx)\in S\}$, rejeitaremos $H_0$ se $\bx \in R$. Pelo Teorema da Fatorização, dado que $T(\bX)$ é suficiente, a verossimilhança de $\bX$ pode ser escrita como $f_n(\bx|\theta_i)=g(T(\bx)|\theta_i)u(\bx),\,i=0,1$, para alguma função $u(\bx)\geq 0$.
	
	Multiplicando tal função nas desigualdades (\ref{col1}) temos:
	
	\begin{align*}
		&g(T(\bx)|\theta_1)\geq kg(T(\bx)|\theta_0)\\
		\Leftrightarrow&
		g(T(\bx)|\theta_1)u(\bx)\geq kg(T(\bx)|\theta_0)u(\bx)\\
		\Leftrightarrow&f_n(\bx|\theta_1)\geq kf_n(\bx|\theta_0)
	\end{align*}
	
	Assim, tem-se: $f_n(\bx|\theta_1)\geq kf_n(\bx|\theta_0)\implies T(\bx)\in S\implies \bx \in R$.
	
	Analogamente, $f_n(\bx|\theta_1)\leq kf_n(\bx|\theta_0)\implies \bx \in R\pow C$.
	
	
	De (\ref{col2}), tem-se:
	
	\begin{align*}
		\pr(\bX\in R|\theta=\theta_0)=\pr[T(\bX)\in S|\theta = \theta_0] = \alpha_0	
	\end{align*}
	
	Pelo \textbf{Lema de Neyman-Pearson} concluímos que o teste $\delta$ é UMP ao nível $\alpha_0$.
	
	
	Voltando agora ao problema inicial da seção, queremos provar que $\delta\pow*$ é UMP ao nível $\alpha_0$ para $H_0:\theta=\theta_0$.
	
	Primeiramente precisamos provar que $\alpha(\delta\pow*)=\alpha_0$.
	
	\begin{align*}
	\displaystyle\alpha(\delta\pow*)&=\sup_{\theta\in\Omega_0}\pi(\theta|\delta\pow*)\\
	&=\sup_{\theta\in\Omega_0}\pr[r(\bX)\geq c|\theta]
	\end{align*}
	
	Como $\Omega_0=\{\theta_0\}$, o supremo ocorre em $\theta_0$ o que implica que $\alpha(\delta\pow*)=\alpha_0$.
	
	Agora precisamos provar que $\delta\pow*$ é UMP.
	
	Façamos $\theta'$ arbitrário, com $\theta'\neq \theta_0$, testaremos $H_0:\theta=\theta_0$ contra $H_1':\theta=\theta'$.  No problema em questão, vale o \textbf{Teorema da Fatorização} para $r(\bX)$, logo assumindo sua suficiência, temos que a verossimilhança pode ser escrita como $f_n(\bx|\theta)=g(r(\bx)|\theta)u(\bx)$, para alguma função $u(\bx)\geq0$.
	
	Seja $t=r(\bx)$; Definamos:
	
	\begin{align*}
		k=\inf_{t\in\mathcal{T}}\dfrac{f_n(\bx|\theta')}{f_n(\bx|\theta_0)}=\dfrac{g(t|\theta')}{g(t|\theta_0)}
	\end{align*}
	
	Com $\mathcal{T}:\defn\{t|t\geq c\}$
	
	Tal ínfimo existe, pois pelo Teorema da Fatorização, a função $g$ é não-negativa, logo, o conjunto na qual estamos tomando ínfimo é limitado inferiormente por 0. Pelo análogo do Axioma do Supremo para ínfimos, $k$ está bem definido.
	
	Pela definição de ínfimo segue que:
	
	$r(\bx)\geq c\Leftrightarrow \dfrac{g(r(\bx)|\theta')}{g(r(\bx)|\theta_0)}\geq k$.
	
	Pelo Corolário \ref{colnp} do Lema de Neyman-Pearson, temos que $\delta\pow*$ é UMP para as hipóteses $H_0:\theta=\theta_0$ e $H_1':\theta=\theta'$, ou seja, $\pi(\theta|\delta\pow*)\geq\pi(\theta'|\delta)$, para qualquer teste $\delta$ de tamanho $\alpha_0$. Como $\theta'$ foi escolhido arbitrariamente diferente de $\theta_0$, temos que $\delta\pow*$ satisfaz $\pi(\theta|\delta\pow*)\geq\pi(\theta'|\delta)~\forall\,\theta'\neq\theta_0$, o que prova nossa afirmação inicial. $\blacksquare$
	
	
	
	
	
	
	
	
	
	% \bibliographystyle{apalike}
	% \bibliography{refs}
	
\end{document}        